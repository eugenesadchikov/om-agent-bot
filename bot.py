import os
import logging
import sys
from io import BytesIO
from dotenv import load_dotenv

# --- –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è Telegram ---
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# --- –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è PDF –∏ –ò–ò ---
import PyPDF2
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import openai

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")

if not TELEGRAM_BOT_TOKEN or not GITHUB_TOKEN:
    print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–∫–µ–Ω—ã –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è GitHub Models
client = openai.OpenAI(
    base_url="https://models.inference.ai.azure.com",
    api_key=GITHUB_TOKEN,
)

MODEL_NAME = "gpt-4o"

# –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[logging.StreamHandler(sys.stdout)]  # –í–∞–∂–Ω–æ –¥–ª—è PythonAnywhere
)
logger = logging.getLogger(__name__)

# ========== –ë–ê–ó–ê –ó–ù–ê–ù–ò–ô ==========
class KnowledgeBase:
    def __init__(self):
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.documents = []
        self.index = None

    def add_document(self, text):
        if not text:
            return
        chunks = [text[i:i+500] for i in range(0, len(text), 500)]
        self.documents.extend(chunks)
        
        new_embeddings = self.embedder.encode(chunks)
        
        if self.index is None:
            dimension = new_embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dimension)
            self.index.add(new_embeddings.astype(np.float32))
        else:
            self.index.add(new_embeddings.astype(np.float32))
        
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤. –í—Å–µ–≥–æ: {len(self.documents)}")

    def search(self, query, k=3):
        if self.index is None or self.index.ntotal == 0:
            return []
        query_embedding = self.embedder.encode([query])
        distances, indices = self.index.search(query_embedding.astype(np.float32), k)
        results = [self.documents[i] for i in indices[0] if i < len(self.documents)]
        return results

knowledge_base = KnowledgeBase()

# ========== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ü–†–û–°–ê –ö –ò–ò ==========
def get_ai_response(prompt):
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π —Å –∞–ª–≥–æ—Ä–∏—Ç–º–∏–∑–∞—Ü–∏–µ–π –∑–∞–¥–∞—á –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000,
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GitHub Models: {e}")
        return None

# ========== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ==========
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –ª–∏—á–Ω—ã–π –ò–ò-–∞–≥–µ–Ω—Ç.\n\n"
        "üìÑ –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ PDF-—Ñ–∞–π–ª —Å —Ç–µ–æ—Ä–∏–µ–π, –∏ —è –µ–≥–æ –∏–∑—É—á—é.\n"
        "‚ùì –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –º–∞—Ç–µ—Ä–∏–∞–ª—É."
    )

async def handle_pdf(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üì• –ü–æ–ª—É—á–∞—é —Ñ–∞–π–ª, –∏–∑—É—á–∞—é...")
    
    file = await update.message.effective_attachment.get_file()
    pdf_bytes = BytesIO()
    await file.download_to_memory(pdf_bytes)
    
    text = ""
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_bytes)
        for page in pdf_reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF.")
        return
    
    if not text.strip():
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF.")
        return
    
    knowledge_base.add_document(text)
    await update.message.reply_text(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –Ø –∑–∞–ø–æ–º–Ω–∏–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ PDF. –¢–µ–ø–µ—Ä—å –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã.")

async def handle_question(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_question = update.message.text
    await update.message.reply_text("ü§î –î—É–º–∞—é –Ω–∞–¥ –≤–æ–ø—Ä–æ—Å–æ–º...")
    
    relevant_chunks = knowledge_base.search(user_question)
    
    if not relevant_chunks:
        await update.message.reply_text(
            "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF-—Ñ–∞–π–ª."
        )
        return
    
    context_text = "\n\n---\n\n".join(relevant_chunks)
    prompt = f"""–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∏–∂–µ, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö ‚Äî —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å.

–î–æ–∫—É–º–µ–Ω—Ç—ã:
{context_text}

–í–æ–ø—Ä–æ—Å: {user_question}

–û—Ç–≤–µ—Ç:"""
    
    answer = get_ai_response(prompt)
    
    if answer:
        await update.message.reply_text(answer)
    else:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.error(f"–û—à–∏–±–∫–∞: {context.error}")

# ========== –ó–ê–ü–£–°–ö –ë–û–¢–ê ==========
def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞"""
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.FileExtension("pdf"), handle_pdf))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_question))
    app.add_error_handler(error_handler)
    
    logger.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
